{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb59784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7a5c2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "directory = \"cleaned\"\n",
    "input_dir = Path(\"output\")\n",
    "output_dir = Path(directory)\n",
    "\n",
    "if (os.path.exists(directory)):\n",
    "    shutil.rmtree(directory)\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Pattern to detect the beginning of a chunk, e.g., (0), (1), etc.\n",
    "chunk_start_pattern = re.compile(r\"^\\((\\d+)\\)\")\n",
    "\n",
    "def clean_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Walk through the file backwards and collect unique rank chunks\n",
    "    seen_ranks = set()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for line in reversed(lines):\n",
    "        if chunk_start_pattern.match(line):\n",
    "            rank = chunk_start_pattern.match(line).group(1)\n",
    "            if rank not in seen_ranks:\n",
    "                seen_ranks.add(rank)\n",
    "                current_chunk.insert(0, line)  # prepend the starting line\n",
    "                chunks.insert(0, current_chunk)  # prepend the entire chunk\n",
    "            current_chunk = []\n",
    "        else:\n",
    "            current_chunk.insert(0, line)  # prepend each line to current_chunk\n",
    "\n",
    "    # Flatten the chunks\n",
    "    cleaned_lines = [line for chunk in chunks for line in chunk]\n",
    "\n",
    "    return cleaned_lines\n",
    "\n",
    "# Process each file\n",
    "for file in input_dir.glob(\"*.out\"):\n",
    "    cleaned_lines = clean_file(file)\n",
    "    output_file = output_dir / file.name\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.writelines(cleaned_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17f8d8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "pattern = re.compile(r'^([a-zA-Z0-9_]+)-(\\d+)-(\\d+)\\.out$')\n",
    "\n",
    "if not os.path.isdir(directory):\n",
    "    raise FileNotFoundError(f\"Directory '{directory}' does not exist.\")\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    match = pattern.match(filename)\n",
    "    if not match:\n",
    "        print(f\"Skipping invalid filename: {filename}\")\n",
    "        continue\n",
    "\n",
    "    algorithm, cluster_size, msg_size = match.groups()\n",
    "    cluster_size = int(cluster_size)\n",
    "    msg_size = int(msg_size)\n",
    "\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    with open(filepath, 'r') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    data[algorithm][cluster_size][msg_size] = content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16a29626",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_pattern = re.compile(r'\\(\\d+\\)\\s+[^=]+=\\s*([-\\d.eE]+):')\n",
    "max_ar_values = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "for algorithm in data:\n",
    "    for cluster in data[algorithm]:\n",
    "        for message in data[algorithm][cluster]:\n",
    "            text = data[algorithm][cluster][message]\n",
    "            ar_matches = ar_pattern.findall(text)\n",
    "\n",
    "            if not ar_matches:\n",
    "                max_ar = None\n",
    "            else:\n",
    "                ar_values = [float(ar) for ar in ar_matches]\n",
    "                max_ar = max(ar_values)\n",
    "\n",
    "            max_ar_values[algorithm][cluster][message] = max_ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cc02b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.exists('graphs'):\n",
    "#     shutil.rmtree('graphs')\n",
    "os.makedirs('graphs', exist_ok=True)\n",
    "\n",
    "# Precompute baseline values for normalization\n",
    "baseline = {}\n",
    "for cluster in max_ar_values.get(\"ring\", {}):\n",
    "    baseline[cluster] = max_ar_values[\"ring\"][cluster]\n",
    "\n",
    "clusters = set()\n",
    "for algorithm in max_ar_values:\n",
    "    clusters.update(max_ar_values[algorithm].keys())\n",
    "\n",
    "for cluster in sorted(clusters):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    for algorithm in sorted(max_ar_values.keys()):\n",
    "        if cluster not in max_ar_values[algorithm]:\n",
    "            continue\n",
    "        if cluster not in baseline:\n",
    "            continue  # Skip if there's no ring baseline to compare to\n",
    "\n",
    "        message_ar = max_ar_values[algorithm][cluster]\n",
    "        baseline_ar = baseline[cluster]\n",
    "\n",
    "        sorted_msgs = sorted(message_ar.keys())\n",
    "        x = []\n",
    "        y = []\n",
    "        for msg in sorted_msgs:\n",
    "            if msg not in baseline_ar:\n",
    "                continue  # Can't normalize without a baseline\n",
    "            base = baseline_ar[msg]\n",
    "            val = message_ar[msg]\n",
    "            if base and val is not None:\n",
    "                x.append(msg)\n",
    "                # y.append(base / val)\n",
    "                y.append(val)\n",
    "            else:\n",
    "                x.append(msg)\n",
    "                y.append(float('nan'))  # Optional: or skip\n",
    "\n",
    "        plt.plot(x, y, label=algorithm, marker='o')\n",
    "\n",
    "    plt.title(f\"Latency vs Message Size (Cluster Size = {cluster})\")\n",
    "    plt.xlabel(\"Message Size\")\n",
    "    plt.xscale(\"log\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.ylabel(\"Latency\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    filename = f\"graphs/perf-{cluster}.png\"  # customize the filename\n",
    "    plt.savefig(filename)\n",
    "\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12727fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mticker\n",
    "\n",
    "os.makedirs('graphs', exist_ok=True)\n",
    "\n",
    "chunk_header_re = re.compile(r\"\\((\\d+)\\)\\s+[^\\n]*=\\s+([0-9eE\\.\\-]+):\")\n",
    "value_line_re = re.compile(r\"^\\s*\\w+:\\s*([-\\d\\.eE]+)\\s*/\\s*[-\\d\\.eE]+\")\n",
    "\n",
    "for algorithm in data:\n",
    "    for cluster_size in data[algorithm]:\n",
    "        # Build a dict of: rank → {msg_size → chunk string}\n",
    "        rank_data = {i: {} for i in range(cluster_size)}\n",
    "\n",
    "        for msg_size in data[algorithm][cluster_size]:\n",
    "            raw = data[algorithm][cluster_size][msg_size]\n",
    "            chunks = re.split(r\"\\n(?=\\(\\d+\\))\", raw.strip())\n",
    "\n",
    "            for chunk in chunks:\n",
    "                match = chunk_header_re.match(chunk)\n",
    "                if match:\n",
    "                    rank = int(match.group(1))\n",
    "                    if rank < cluster_size:\n",
    "                        rank_data[rank][msg_size] = chunk\n",
    "\n",
    "        # Create subplots: one per rank\n",
    "        fig, axs = plt.subplots(cluster_size, 1, figsize=(10, 3 * cluster_size), sharex=False)\n",
    "        if cluster_size == 1:\n",
    "            axs = [axs]\n",
    "\n",
    "        fig.suptitle(f\"Algorithm: {algorithm}, Cluster Size: {cluster_size}\")\n",
    "\n",
    "        for rank in range(cluster_size):\n",
    "            ax = axs[rank]\n",
    "            ax.set_title(f\"Proc. {rank}\")\n",
    "            n_round = 0\n",
    "            for msg_size in sorted(rank_data[rank]):\n",
    "                chunk = rank_data[rank][msg_size]\n",
    "                lines = chunk.strip().splitlines()\n",
    "                cumulative = []\n",
    "                total = 0.0\n",
    "                for line in lines:\n",
    "                    match = value_line_re.match(line)\n",
    "                    if match:\n",
    "                        try:\n",
    "                            val = float(match.group(1))\n",
    "                            total += val\n",
    "                            cumulative.append(total)\n",
    "                        except ValueError:\n",
    "                            continue\n",
    "\n",
    "                # Normalize cumulative list to end at 1.0\n",
    "                if cumulative and cumulative[-1] != 0:\n",
    "                    normalized = [v / cumulative[-1] for v in cumulative]\n",
    "                    ax.plot(range(1, len(normalized) + 1), normalized,\n",
    "                            label=f\"msg={msg_size}\", marker='o')\n",
    "                n_round = len(cumulative)\n",
    "\n",
    "            ax.xaxis.set_major_locator(mticker.MaxNLocator(integer=True))\n",
    "            # if (algorithm == \"circ_rs_ag\"):\n",
    "            #     ax.axvline(x=2 -0.1, color='red', linestyle='--')\n",
    "            #     ax.axvline(x=n_round-1+0.1, color='red', linestyle='--')\n",
    "            #     ax.axvline(x=((n_round-3)/2)+2, color='red', linestyle='--')\n",
    "            ax.set_xlabel(\"Step\")\n",
    "            ax.set_ylabel(\"Progress\")\n",
    "            ax.grid(True)\n",
    "            ax.legend()\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "        filename = f\"graphs/{algorithm}_{cluster_size}.png\"  # customize the filename\n",
    "        plt.savefig(filename)\n",
    "\n",
    "        plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
